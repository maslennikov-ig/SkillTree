# Teen Career Assessment Q1: Keep Forced-Choice, Reframe for Honesty

**The evidence strongly favors maintaining a forced-choice format without passive leisure options, but with a subtle reframe from "what you will do" to "what you would enjoy" to address the perceived dishonesty concern.** Major validated career assessmentsâ€”O*NET, Strong Interest Inventory, ACT Interest Inventory, and Kuderâ€”deliberately exclude passive entertainment options because they don't predict vocational outcomes. Adding a 5th neutral option risks creating a "dump option" that reduces profile differentiation, while hypothetical constraints like "weekend without gadgets" lack validity evidence and add cognitive complexity. The solution lies in reframing the question from asking about actual weekend behavior to asking about preferred activities, which feels more authentic while preserving psychometric integrity.

---

## Established assessments exclude passive leisure by design

The O*NET Interest Profiler Manual explicitly states that developers "removed non-work activities" during item construction, and the instrument instructs users "not to think about hobbies-only activities." Holland's Self-Directed Search maintains a separate "Leisure Activities Finder" toolâ€”kept deliberately distinct from the career assessment. The Strong Interest Inventory includes an "Indifferent" response option but applies it only to work-relevant activities, scoring it at zero. The ACT Interest Inventory emphasizes "work-relevant activities familiar to people through participation or observation" while avoiding occupational titles that might confuse career-exploration beginners.

The theoretical justification is clear: career interest inventories measure **vocational personality** to predict person-environment fit in work contexts. Passive entertainment doesn't map to the RIASEC hexagon and provides no predictive validity for career outcomes. Research comparing leisure versus occupational criteria found "greater congruence between interest scales and occupations than interest scales and leisure activities." When the army developed its Adaptive Vocational Interest Diagnostic (AVID), items were specifically matched on social desirability to prevent respondents from selecting based on job prestige rather than genuine interestâ€”including socially undesirable passive options would undermine this design principle.

---

## Neutral options carry measurable psychometric risks

If SkillTree adds a 5th "gaming/videos" option, scoring becomes problematic. The O*NET handles its "Not Sure" response by treating it as functionally equivalent to "Dislike"â€”no score benefit whatsoever. The Strong Interest Inventory scores "Indifferent" at true zero. Both approaches prevent the neutral option from becoming a low-effort default choice. Research on midpoint response styles shows that neutral options are interpreted in **16+ different ways** including "no opinion," "don't care," "unsure," and "depends"â€”introducing construct contamination.

The real danger is **profile flattening**. Holland's diagnostic framework uses "differentiation"â€”the difference between highest and lowest RIASEC scoresâ€”as a validity indicator. When respondents select many neutral options, their profiles become undifferentiated, reducing the assessment's ability to recommend appropriate careers. Studies suggest flagging profiles where neutral responses exceed **30-40%** as potentially invalid. For a 55-question assessment targeting teens who might prefer a low-effort response, this threshold could be reached quickly if a tempting neutral option exists.

If SkillTree nevertheless adds a neutral option, the scoring should be:
- **Zero contribution** to all RIASEC dimensions
- Track neutral response rates as a validity indicator
- Flag profiles with >30% neutral responses for counselor review
- Calculate differentiation scores and trigger additional guidance for flat profiles

---

## Hypothetical constraints introduce problems without solving them

The "weekend without gadgets" framing (Option B) lacks empirical support. Survey methodology research consistently warns against hypothetical questions because they "assume certain conditions exist" and "should be implemented with great care." Adding artificial constraints introduces three validity threats:

1. **Construct contamination**: The assessment begins measuring compliance with an imaginary limitation rather than authentic career-related interests
2. **Increased cognitive load**: Teens must imagine an artificial scenario rather than accessing genuine preferences
3. **Social desirability shift**: The constraint implies that gadget-free activities are more valuable, potentially biasing responses toward perceived "correct" answers

Landmark research by Ployhart and Ehrhart (2003) found that situational judgment test instructions have "large effects on responses, reliability, and validity." For non-cognitive constructs like career interests, "would do/would like" framing outperforms "should do" framing because interests align with personality traits rather than knowledge. The validated approach across O*NET, ACT, Strong, and Kuder inventories is straightforward activity preferenceâ€”not hypothetical scenarios.

---

## First-question effects are significant for teen engagement

Research across **25,000+ surveys** found that surveys starting with multiple-choice questions have **5 percentage points higher completion rates** than those starting with open-ended questions. The first question "sets the tone" and if perceived as easy, respondents are "more likely to continue with all subsequent questions." For teens specifically, forced-choice formats demonstrated **better model fit, reliability, and validity** than Likert alternatives across samples of 5th-11th gradersâ€”despite concerns that forced-choice might be too cognitively complex for adolescents.

However, engagement research also shows that when respondents feel "no option represents them," problematic response patterns emerge: random selection, straight-lining, and increased dropout. The key insight is that **perceived option relevance matters**â€”but the solution isn't adding irrelevant options; it's ensuring existing options feel genuine and accessible. Mobile-optimized assessments achieving **89% completion rates** with teens use brief (2-3 minute), clearly-worded questions about familiar activities with simple response formats.

---

## The real problem is behavioral framing, not missing options

The current question asks "Weekend! What **will** you do?" (Ð§ÐµÐ¼ **Ð·Ð°Ð¹Ð¼Ñ‘ÑˆÑŒÑÑ**?)â€”implying a prediction of actual behavior. This creates the perceived dishonesty: teens know their actual weekend behavior includes gaming and cartoons, making the question feel inauthentic. But the issue isn't missing options; it's that behavioral framing conflates what teens **currently do** (which reflects access, habit, and environment) with what they **genuinely prefer** (which predicts vocational personality).

Validated career assessments use preference-based framing. The ACT Interest Inventory asks teens to rate how much they would "like" activities. O*NET Interest Profiler uses "Strongly Like to Strongly Dislike." Strong Interest Inventory uses "Like/Indifferent/Dislike." None ask what respondents "will" do or "actually" doâ€”they ask about enjoyment of activities.

A simple reframe from "What **will** you do?" to "What would you **enjoy** doing?" resolves the authenticity concern without adding invalid options. The teen who knows they'll actually watch cartoons can honestly select "I'd enjoy meeting friends" if that's their genuine preference when they imagine having a choice between the four activitiesâ€”even if passive leisure typically wins by default.

---

## Specific recommendation and implementation

**Keep the 4-option forced-choice format (Option C)** but reframe the question from behavioral prediction to preference expression. This maintains psychometric validity while addressing the perceived dishonesty.

**Proposed Russian Text:**
```
ðŸŽ® Ð’Ñ‹Ñ…Ð¾Ð´Ð½Ð¾Ð¹! ÐšÐ°ÐºÐ¾Ðµ Ð·Ð°Ð½ÑÑ‚Ð¸Ðµ Ñ‚ÐµÐ±Ðµ Ð¿Ð¾ Ð´ÑƒÑˆÐµ?
(Weekend! Which activity appeals to you?)

A) ðŸ”§ Ð¡Ð¾Ð±Ñ€Ð°Ñ‚ÑŒ Ð¸Ð»Ð¸ Ð¿Ð¾Ñ‡Ð¸Ð½Ð¸Ñ‚ÑŒ Ñ‡Ñ‚Ð¾-Ð½Ð¸Ð±ÑƒÐ´ÑŒ Ñ€ÑƒÐºÐ°Ð¼Ð¸ [R: 1.0]
B) ðŸ“š ÐŸÐ¾ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ Ð½Ð°ÑƒÑ‡Ð¿Ð¾Ð¿ Ð¸Ð»Ð¸ Ð¿Ð¾Ñ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾Ðµ [I: 1.0]  
C) ðŸŽ¨ ÐŸÐ¾Ñ€Ð¸ÑÐ¾Ð²Ð°Ñ‚ÑŒ Ð¸Ð»Ð¸ Ð¿Ð¾Ð·Ð°Ð½Ð¸Ð¼Ð°Ñ‚ÑŒÑÑ Ñ‚Ð²Ð¾Ñ€Ñ‡ÐµÑÑ‚Ð²Ð¾Ð¼ [A: 1.0]
D) ðŸ‘¥ Ð’ÑÑ‚Ñ€ÐµÑ‚Ð¸Ñ‚ÑŒÑÑ Ñ Ð´Ñ€ÑƒÐ·ÑŒÑÐ¼Ð¸ Ð¸Ð»Ð¸ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ ÐºÐ¾Ð¼Ñƒ-Ñ‚Ð¾ [S: 1.0]
```

**Key changes:**
- "Ð§ÐµÐ¼ Ð·Ð°Ð¹Ð¼Ñ‘ÑˆÑŒÑÑ?" (What will you do?) â†’ "ÐšÐ°ÐºÐ¾Ðµ Ð·Ð°Ð½ÑÑ‚Ð¸Ðµ Ñ‚ÐµÐ±Ðµ Ð¿Ð¾ Ð´ÑƒÑˆÐµ?" (Which activity appeals to you?)
- This shifts from behavioral prediction to preference expression
- Maintains informal "Ñ‚Ñ‹" register appropriate for teens
- Keeps familiar, concrete activities that map cleanly to RIASEC dimensions

**Alternative framings tested:**
- "Ð§Ñ‚Ð¾ Ð±Ð¾Ð»ÑŒÑˆÐµ Ñ…Ð¾Ñ‚ÐµÐ»Ð¾ÑÑŒ Ð±Ñ‹ ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ?" (What would you want to do more?)
- "Ð§ÐµÐ¼ Ð±Ñ‹ Ð·Ð°Ð½ÑÐ»ÑÑ Ñ ÑƒÐ´Ð¾Ð²Ð¾Ð»ÑŒÑÑ‚Ð²Ð¸ÐµÐ¼?" (What would you enjoy doing?)
- "ÐšÐ°ÐºÐ¾Ð¹ Ð¾Ñ‚Ð´Ñ‹Ñ… Ñ‚ÐµÐ±Ðµ Ð±Ð»Ð¸Ð¶Ðµ?" (Which leisure suits you best?)

**Why not add a 5th option:**
If stakeholders insist on testing a neutral option despite the evidence, use this scoring to prevent dump-option behavior:
```
E) ðŸŽ® ÐŸÐ¾ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ ÑÐµÑ€Ð¸Ð°Ð» Ð¸Ð»Ð¸ Ð¿Ð¾Ð¸Ð³Ñ€Ð°Ñ‚ÑŒ Ð² Ð¸Ð³Ñ€Ñ‹ 
[R: 0, I: 0, A: 0, S: 0, E: 0, C: 0]
```
Track selection rates. If >25% of respondents select this option, consider removing itâ€”the profile differentiation loss outweighs any engagement benefit.

---

## Conclusion: Honesty comes from framing, not comprehensiveness

The tester's concern that 60% of kids want to watch cartoons reflects a mismatch between **what teens actually do** on weekends and **what the assessment measures**. Career interest inventories aren't designed to capture actual time allocationâ€”they measure latent vocational preferences that predict career fit. Major validated instruments deliberately exclude passive leisure because it doesn't predict occupational outcomes.

The solution isn't making the assessment more comprehensive by adding gaming options; it's making the question feel more authentic by asking about preferences rather than behaviors. When a teen reads "Which activity appeals to you?" they can honestly answer based on genuine interestâ€”even if their actual weekend includes hours of YouTube. The forced-choice format works because career decisions ultimately require choosing between work activities, not between working and not working. By reframing Q1 as a preference expression rather than a behavioral prediction, SkillTree maintains psychometric validity while eliminating the perceived dishonesty that prompted the original concern.